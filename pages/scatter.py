import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from utils.error_calculator import calculate_error_rates, calculate_weighted_average_error_rate
from config.constants import UNIFIED_COLOR_PALETTE, PREDICTION_TYPE_NAMES

def show():
    """æ•£å¸ƒå›³åˆ†æãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º"""
    # CSSã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆUI/UXã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³æº–æ‹ ï¼‰ã®é©ç”¨
    st.markdown("""
    <style>
    /* STEPæ³¨é‡ˆãƒ»èª¬æ˜æ–‡ */
    .step-annotation {
        color: #666666;
        font-size: 0.95em;
        margin-bottom: 1.2em;
    }

    /* å¤§é …ç›®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒœãƒƒã‚¯ã‚¹ï¼ˆSTEPã‚¹ã‚¿ã‚¤ãƒ«çµ±ä¸€ï¼‰ */
    .section-header-box {
        background: #e8f4fd;
        color: #1976d2;
        padding: 1rem 1.5rem;
        border-radius: 12px;
        text-align: left;
        margin-bottom: 1rem;
        box-shadow: 0 1px 4px rgba(33, 150, 243, 0.1);
    }

    .section-header-box h2 {
        font-size: 1.9rem;
        margin: 0 0 0.2rem 0;
        font-weight: 600;
        color: #1976d2;
    }

    .section-header-box p {
        font-size: 1.05rem;
        margin: 0;
        color: #4a90e2;
        line-height: 1.6;
    }

    /* STEPè¦‹å‡ºã—ï¼ˆé’ç·šä»˜ãã‚¿ã‚¤ãƒˆãƒ«ï¼‰ */
    .step-title {
        font-size: 1.4em;
        font-weight: bold;
        color: #1976d2;
        border-left: 4px solid #1976d2;
        padding-left: 12px;
        margin-bottom: 1em;
        margin-top: 2em;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # â‘  å¤§é …ç›®ãƒ‡ã‚¶ã‚¤ãƒ³ä¿®æ­£ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆã¨åŒã˜éšå±¤ã®è¦‹å‡ºã—ã‚¹ã‚¿ã‚¤ãƒ«ï¼‰
    st.markdown("""
    <div class="section-header-box">
        <h2>â–  æ•£å¸ƒå›³åˆ†æï¼ˆèª¤å·®ç‡æ•£å¸ƒå›³ãƒ»äºˆæ¸¬å€¤vså®Ÿç¸¾å€¤æ•£å¸ƒå›³ï¼‰</h2>
        <p>ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€åˆ†é¡å˜ä½ã§ABCåŒºåˆ†åˆ¥ã®èª¤å·®ç‡ã‚’å¤šè§’çš„ã«åˆ†æãƒ»å¯è¦–åŒ–ã—ã€å„åŒºåˆ†ã«ãŠã‘ã‚‹èª¤å·®ã®å‚¾å‘ã‚„ç‰¹å¾´ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã™ã€‚</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ãƒ‡ãƒ¼ã‚¿ç¢ºèª
    if st.session_state.data is None:
        st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        return
    
    df = st.session_state.data
    
    # â‘¢ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é …ç›®ã®è¿½åŠ ï¼šã€Œåˆ†é¡ã€ã€ŒæœŸé–“ã€ã®é †ã§é…ç½®
    filtered_df = apply_filters(df)
    
    if filtered_df.empty:
        st.warning("âš ï¸ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # â‘¡ ABCåŒºåˆ†åˆ¥åŠ é‡å¹³å‡èª¤å·®ç‡è¡¨ã‚’ä¸­é …ç›®è¦‹å‡ºã—ã‚¹ã‚¿ã‚¤ãƒ«ã§è¡¨ç¤º
    if 'Class_abc' in filtered_df.columns:
        prediction_columns = ['AI_pred', 'Plan_01']
        if 'Plan_02' in df.columns:
            prediction_columns.append('Plan_02')
        
        abc_avg_errors = calculate_abc_average_errors(filtered_df, prediction_columns)
        display_abc_average_table(abc_avg_errors, filtered_df)
    
    # ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒ—é¸æŠã¨ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š
    st.markdown("---")
    
    col1, col2 = st.columns(2)
    
    with col1:
        plot_type = st.selectbox(
            "ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒ—",
            ['èª¤å·®ç‡æ•£å¸ƒå›³ï¼ˆæ¨ªè»¸ï¼šèª¤å·®ç‡ ï¼ ç¸¦è»¸ï¼šè¨ˆç”»å€¤ï¼‰', 'äºˆæ¸¬å€¤ vs å®Ÿç¸¾å€¤æ•£å¸ƒå›³'],
            key="plot_type_selector"
        )
    
    with col2:
        prediction_columns = ['AI_pred', 'Plan_01']
        if 'Plan_02' in df.columns:
            prediction_columns.append('Plan_02')
        
        # åˆæœŸé¸æŠã¯å…¨ã¦
        default_selections = prediction_columns
        
        selected_predictions = st.multiselect(
            "è¡¨ç¤ºã™ã‚‹äºˆæ¸¬ãƒ»è¨ˆç”»",
            prediction_columns,
            default=default_selections,
            format_func=get_prediction_name,
            key="prediction_selector"
        )
    
    # â‘£ ä¸è¦ãªã€Œå¯¾æ¯”ã™ã‚‹äºˆæ¸¬ãƒ»è¨ˆç”»ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’å‰Šé™¤
    
    if not selected_predictions:
        st.warning("âš ï¸ è¡¨ç¤ºã™ã‚‹äºˆæ¸¬ãƒ»è¨ˆç”»ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨ˆç®—ï¼ˆåˆ†é¡ã”ã¨ã«æœ€é©åŒ–ï¼‰
    default_y_max = get_optimal_y_max(filtered_df, selected_predictions)
    
    # åˆ†é¡ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å€¤ã¨æ¯”è¼ƒå¯¾è±¡ã‚’å–å¾—ï¼ˆã‚­ãƒ¼ç”Ÿæˆã®ãŸã‚ï¼‰
    current_category = st.session_state.get('category_filter', 'å…¨ã¦')
    current_date = st.session_state.get('date_filter', 'å…¨æœŸé–“')
    predictions_key = '_'.join(sorted(selected_predictions))  # æ¯”è¼ƒå¯¾è±¡ã‚‚ã‚­ãƒ¼ã«å«ã‚ã‚‹
    filter_key = f"{current_category}_{current_date}_{predictions_key}"
    
    # å‰å›ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å€¤ã‚’è¨˜éŒ²ãƒ»æ¯”è¼ƒ
    previous_filter_key = st.session_state.get('previous_filter_key', '')
    if previous_filter_key != filter_key:
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¾ãŸã¯æ¯”è¼ƒå¯¾è±¡ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã€å¤ã„ã‚­ãƒ¼ã®å€¤ã‚’ã‚¯ãƒªã‚¢
        st.session_state['previous_filter_key'] = filter_key
        # æ—¢å­˜ã®è»¸ã‚¹ã‚±ãƒ¼ãƒ«è¨­å®šã‚’ãƒªã‚»ãƒƒãƒˆ
        for key in list(st.session_state.keys()):
            if key.startswith('x_min_scatter_') or key.startswith('x_max_scatter_') or key.startswith('y_max_scatter_'):
                if key != f"x_min_scatter_{filter_key}" and key != f"x_max_scatter_{filter_key}" and key != f"y_max_scatter_{filter_key}":
                    del st.session_state[key]
    
    # è»¸ã‚¹ã‚±ãƒ¼ãƒ«è¨­å®šUIï¼ˆè¦‹å‡ºã—ãªã—ã€ã‚°ãƒ©ãƒ•å‰ã«é…ç½®ï¼‰
    col1, col2, col3 = st.columns(3)
    
    with col1:
        x_min_input = st.number_input(
            "æ¨ªè»¸æœ€å°å€¤ (%)",
            value=-100,
            step=10,
            format="%d",
            key=f"x_min_scatter_{filter_key}"
        )
    
    with col2:
        x_max_input = st.number_input(
            "æ¨ªè»¸æœ€å¤§å€¤ (%)",
            value=200,
            step=10,
            format="%d",
            key=f"x_max_scatter_{filter_key}"
        )
    
    with col3:
        # ç¸¦è»¸æœ€å¤§å€¤ã®è‡ªå‹•æœ€é©åŒ–ï¼ˆæ¯”è¼ƒå¯¾è±¡å¤‰æ›´æ™‚ã‚‚å«ã‚€ï¼‰
        current_y_max = default_y_max
        
        # å‰å›ã¨åŒã˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã§ã€ã‹ã¤ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ‰‹å‹•èª¿æ•´æ¸ˆã¿ã®å ´åˆã®ã¿ä¿æŒ
        # ãŸã ã—ã€æ¯”è¼ƒå¯¾è±¡ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã¯æ–°ã—ã„æœ€é©å€¤ã‚’ä½¿ç”¨
        if (previous_filter_key == filter_key and 
            f"y_max_scatter_{filter_key}" in st.session_state):
            # å‰å›ã®å€¤ã‚’å–å¾—
            previous_y_max = st.session_state[f"y_max_scatter_{filter_key}"]
            # å‰å›ã®æœ€é©å€¤ã‚’è¨ˆç®—ï¼ˆæ¯”è¼ƒå¯¾è±¡ãŒå¤‰æ›´ã•ã‚Œã¦ã„ãªã„å ´åˆï¼‰
            previous_optimal = st.session_state.get(f"optimal_y_max_{filter_key}", default_y_max)
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ‰‹å‹•èª¿æ•´ã—ã¦ã„ã‚‹å ´åˆã®ã¿ä¿æŒ
            if previous_y_max != previous_optimal:
                current_y_max = previous_y_max
        
        # ç¾åœ¨ã®æœ€é©å€¤ã‚’è¨˜éŒ²ï¼ˆæ¬¡å›ã®åˆ¤å®šç”¨ï¼‰
        st.session_state[f"optimal_y_max_{filter_key}"] = default_y_max
        
        y_max_input = st.number_input(
            "ç¸¦è»¸æœ€å¤§å€¤",
            value=current_y_max,
            step=100,
            format="%d",
            key=f"y_max_scatter_{filter_key}"
        )

    # æ•£å¸ƒå›³ä½œæˆãƒ»è¡¨ç¤º
    if plot_type == 'èª¤å·®ç‡æ•£å¸ƒå›³ï¼ˆæ¨ªè»¸ï¼šèª¤å·®ç‡ ï¼ ç¸¦è»¸ï¼šè¨ˆç”»å€¤ï¼‰':
        create_error_rate_scatter(filtered_df, selected_predictions, x_min_input/100, x_max_input/100, y_max_input)
    else:
        create_prediction_vs_actual_scatter(filtered_df, selected_predictions)

def apply_filters(df):
    """â‘¢ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®šUIã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆåˆ†é¡ãƒ»æœŸé–“ã®é †ï¼‰"""
    # åˆ†é¡ãŒãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’ç¢ºèª
    has_category = 'category_code' in df.columns and not df['category_code'].isna().all()
    
    if has_category:
        # åˆ†é¡ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚ã‚Šã®å ´åˆ
        col1, col2 = st.columns(2)
        
        with col1:
            # åˆ†é¡ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆåˆæœŸå€¤ï¼šå…¨ã¦ï¼‰
            category_options = ['å…¨ã¦'] + sorted(df['category_code'].dropna().unique().tolist())
            selected_category = st.selectbox("åˆ†é¡", category_options, key="category_filter")
        
        with col2:
            # æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆåˆæœŸå€¤ï¼šå…¨æœŸé–“ï¼‰
            if 'Date' in df.columns:
                date_options = ['å…¨æœŸé–“'] + sorted(df['Date'].dropna().unique().tolist())
                selected_date = st.selectbox("æœŸé–“", date_options, key="date_filter")
            else:
                selected_date = 'å…¨æœŸé–“'
    else:
        # åˆ†é¡ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãªã—ã®å ´åˆï¼ˆæœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®ã¿ï¼‰
        selected_category = 'å…¨ã¦'
        
        # æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆåˆæœŸå€¤ï¼šå…¨æœŸé–“ï¼‰
        if 'Date' in df.columns:
            date_options = ['å…¨æœŸé–“'] + sorted(df['Date'].dropna().unique().tolist())
            selected_date = st.selectbox("æœŸé–“", date_options, key="date_filter")
        else:
            selected_date = 'å…¨æœŸé–“'
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filtered_df = df.copy()
    
    # åˆ†é¡ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    if selected_category != 'å…¨ã¦':
        filtered_df = filtered_df[filtered_df['category_code'] == selected_category]
    
    # æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    if selected_date != 'å…¨æœŸé–“':
        filtered_df = filtered_df[filtered_df['Date'] == selected_date]
    
    return filtered_df

def get_prediction_name(pred_type):
    """äºˆæ¸¬ã‚¿ã‚¤ãƒ—ã®è¡¨ç¤ºåã‚’å–å¾—ï¼ˆã‚«ã‚¹ã‚¿ãƒ é …ç›®åå¯¾å¿œãƒ»6æ–‡å­—çœç•¥å¯¾å¿œï¼‰"""
    # ã‚«ã‚¹ã‚¿ãƒ é …ç›®åãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if 'custom_column_names' in st.session_state and pred_type in st.session_state.custom_column_names:
        custom_name = st.session_state.custom_column_names[pred_type].strip()
        if custom_name:
            # å…¨è§’6æ–‡å­—ã‚’è¶…ãˆã‚‹å ´åˆã¯çœç•¥
            if len(custom_name) > 6:
                return custom_name[:6] + 'â€¦'
            else:
                return custom_name
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåã‚’å–å¾—
    default_name = PREDICTION_TYPE_NAMES.get(pred_type, pred_type)
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåã‚‚6æ–‡å­—ãƒã‚§ãƒƒã‚¯
    if len(default_name) > 6:
        return default_name[:6] + 'â€¦'
    else:
        return default_name

def get_optimal_y_max(df, selected_predictions):
    """â‘¤ åˆ†é¡ã”ã¨ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç¸¦è»¸æœ€å¤§å€¤ã‚’è¨ˆç®—"""
    max_values = []
    for pred_col in selected_predictions:
        if pred_col in df.columns:
            max_val = df[pred_col].max()
            if not pd.isna(max_val):
                max_values.append(max_val)
    
    if max_values:
        overall_max = max(max_values)
        # 10%ã®ãƒãƒ¼ã‚¸ãƒ³ã‚’è¿½åŠ ã—ã€é©åˆ‡ãªå˜ä½ã§ä¸¸ã‚ã‚‹
        margin_added = overall_max * 1.1
        
        # ãƒ‡ãƒ¼ã‚¿è¦æ¨¡ã«å¿œã˜ã¦é©åˆ‡ãªå˜ä½ã§ä¸¸ã‚ã‚‹
        if margin_added <= 100:
            # 100ä»¥ä¸‹ã®å ´åˆï¼š10ã®å€æ•°
            optimized_max = int((margin_added // 10 + 1) * 10)
        elif margin_added <= 1000:
            # 1000ä»¥ä¸‹ã®å ´åˆï¼š50ã®å€æ•°
            optimized_max = int((margin_added // 50 + 1) * 50)
        else:
            # 1000è¶…ã®å ´åˆï¼š100ã®å€æ•°
            optimized_max = int((margin_added // 100 + 1) * 100)
        
        # æœ€ä½å€¤ã¯50ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
        return max(optimized_max, 50)
    else:
        return 1000

def create_error_rate_scatter(df, selected_predictions, x_min, x_max, y_max):
    """èª¤å·®ç‡æ•£å¸ƒå›³ã‚’ä½œæˆï¼ˆâ‘¤ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´å¯¾å¿œã€â‘¥å‡¡ä¾‹ä¿®æ­£ï¼‰"""
    
    # â‘¡ ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä¸­é …ç›®è¦‹å‡ºã—ã‚¹ã‚¿ã‚¤ãƒ«ã§è¡¨ç¤º
    st.markdown('<div class="step-title">èª¤å·®ç‡æ•£å¸ƒå›³ï¼ˆæ¨ªè»¸ï¼šèª¤å·®ç‡ ï¼ ç¸¦è»¸ï¼šè¨ˆç”»å€¤ï¼‰</div>', unsafe_allow_html=True)
    
    # â‘¢ èª¬æ˜æ–‡è¿½åŠ 
    st.markdown(
        '<div class="step-annotation">å„åŒºåˆ†ã®èª¤å·®ç‡ã‚’å•†å“ã‚³ãƒ¼ãƒ‰å˜ä½ã§å¯è¦–åŒ–ã—ã€ã€Œçµ¶å¯¾èª¤å·®ç‡ã€ã€Œè² ã®èª¤å·®ç‡ï¼ˆæ¬ å“ãƒªã‚¹ã‚¯ï¼‰ã€ã€Œæ­£ã®èª¤å·®ç‡ï¼ˆéå‰°åœ¨åº«ãƒªã‚¹ã‚¯ï¼‰ã€ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚</div>',
        unsafe_allow_html=True
    )
    
    try:
        # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
        if df.empty:
            st.warning("âš ï¸ è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
        fig = make_subplots(
            rows=1, 
            cols=len(selected_predictions),
            subplot_titles=[get_prediction_name(pred) for pred in selected_predictions]
        )

        # â‘¥ å‡¡ä¾‹ç”¨ã®åŒºåˆ†ã‚’æ•´ç†ï¼ˆã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆé †ï¼‰
        all_abc_classes = set()
        if 'Class_abc' in df.columns:
            all_abc_classes = set(df['Class_abc'].dropna().unique())
        
        # ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆé †ã«ã‚½ãƒ¼ãƒˆ
        sorted_abc_classes = sorted(list(all_abc_classes))
        
        for i, pred_col in enumerate(selected_predictions):
            try:
                # äºˆæ¸¬ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                if pred_col not in df.columns:
                    st.warning(f"âš ï¸ ã‚«ãƒ©ãƒ  '{pred_col}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                    continue
                
                # èª¤å·®ç‡è¨ˆç®—
                df_with_errors = calculate_error_rates(df, pred_col, 'Actual')
                
                # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ï¼šNaNã€Infå€¤ã‚’é™¤å»
                df_with_errors = df_with_errors.replace([np.inf, -np.inf], np.nan)
                df_with_errors = df_with_errors.dropna(subset=['error_rate', pred_col, 'Actual'])
                
                # å®Ÿç¸¾ãŒã‚¼ãƒ­ã®å ´åˆã‚’é™¤å¤–ï¼ˆè¨ˆç®—ä¸èƒ½ï¼‰
                valid_data = df_with_errors[~df_with_errors['is_actual_zero']].copy()
                
                if valid_data.empty:
                    st.warning(f"âš ï¸ {get_prediction_name(pred_col)} ã®æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                    continue
                
                # æ¥µç«¯ãªå€¤ã‚’åˆ¶é™ï¼ˆã‚°ãƒ©ãƒ•è¡¨ç¤ºç¯„å›²å¤–ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒƒãƒ—ï¼‰
                valid_data.loc[:, 'error_rate'] = valid_data['error_rate'].clip(lower=x_min*2, upper=x_max*2)
                valid_data.loc[:, pred_col] = valid_data[pred_col].clip(lower=0, upper=y_max*2)
                
                # è‰²åˆ†ã‘ç”¨ã®åˆ—ã‚’ä½œæˆï¼ˆABCåŒºåˆ†ãŒã‚ã‚Œã°ä½¿ç”¨ï¼‰
                if 'Class_abc' in df.columns:
                    color_col = 'Class_abc'
                    # ABCåŒºåˆ†ã‚«ãƒ©ãƒ¼ã‚’çµ±ä¸€ãƒ‘ãƒ¬ãƒƒãƒˆã‹ã‚‰å–å¾—
                    color_discrete_map = {k: v for k, v in UNIFIED_COLOR_PALETTE.items() 
                                        if k in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'Z']}
                    # â‘¡ å‡¡ä¾‹ã‚’ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆé †ã«è¡¨ç¤ºã™ã‚‹ãŸã‚ã®category_orders
                    category_orders = {color_col: sorted_abc_classes}
                else:
                    color_col = None
                    color_discrete_map = None
                    category_orders = None
                
                # æ•£å¸ƒå›³ä½œæˆï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
                scatter = px.scatter(
                    valid_data,
                    x='error_rate',
                    y=pred_col,
                    color=color_col,
                    color_discrete_map=color_discrete_map,
                    category_orders=category_orders,
                    hover_data=['P_code', 'Actual', pred_col, 'absolute_error_rate'],
                    title=f"{get_prediction_name(pred_col)}"
                )
                
                # â‘¥ å‡¡ä¾‹ã®è¡¨ç¤ºé †ãƒ»ãƒ©ãƒ™ãƒ«ã®ä¿®æ­£ï¼ˆã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆé †ã€é‡è¤‡è§£æ¶ˆï¼‰
                added_legends = set()
                for trace in scatter.data:
                    if 'Class_abc' in df.columns and trace.name and trace.name in sorted_abc_classes:
                        legend_name = f"{trace.name}åŒºåˆ†"
                        trace.name = legend_name
                        # é‡è¤‡å‰Šé™¤ã®ãŸã‚ã€æ—¢ã«è¿½åŠ æ¸ˆã¿ã®å‡¡ä¾‹ã¯éè¡¨ç¤º
                        if legend_name in added_legends or i > 0:
                            trace.showlegend = False
                        else:
                            added_legends.add(legend_name)
                    elif not trace.name:  # ç©ºã®åå‰ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåã‚’è¨­å®š
                        trace.name = "ãƒ‡ãƒ¼ã‚¿"
                        trace.showlegend = False
                    fig.add_trace(trace, row=1, col=i+1)
                
                # Xè»¸ã«0ã®ç·šã‚’è¿½åŠ 
                fig.add_vline(x=0, line_dash="dash", line_color="gray", 
                             row=1, col=i+1, annotation_text="å®Œå…¨ä¸€è‡´")
                
            except Exception as sub_error:
                st.error(f"âŒ {get_prediction_name(pred_col)} ã®æ•£å¸ƒå›³ä½œæˆã§ã‚¨ãƒ©ãƒ¼: {str(sub_error)}")
                continue
        
        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
        fig.update_layout(
            height=600,
            showlegend=True
        )
        
        # â‘¤ ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚±ãƒ¼ãƒ«é©ç”¨
        fig.update_xaxes(
            title_text="èª¤å·®ç‡", 
            range=[x_min, x_max],
            tickformat='+.0%',
            dtick=0.5
        )
        
        fig.update_yaxes(
            title_text="è¨ˆç”»å€¤",
            range=[0, y_max]
        )
        
        # ã‚°ãƒ©ãƒ•è¡¨ç¤ºï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
        st.plotly_chart(fig, use_container_width=True)
        
        # å‡¡ä¾‹ã«ã‚ˆã‚‹è¡¨ç¤ºåˆ‡æ›¿æ©Ÿèƒ½ã®å‘¨çŸ¥
        st.markdown(
            '<div class="step-annotation">â€» å‡¡ä¾‹é …ç›®ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€è©²å½“ã™ã‚‹åŒºåˆ†ã®è¡¨ç¤º/éè¡¨ç¤ºã‚’åˆ‡ã‚Šæ›¿ãˆã§ãã¾ã™ã€‚</div>',
            unsafe_allow_html=True
        )
        
    except Exception as e:
        st.error(f"âŒ æ•£å¸ƒå›³ã®ä½œæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.info("ğŸ’¡ ä»¥ä¸‹ã®æ–¹æ³•ã‚’ãŠè©¦ã—ãã ã•ã„ï¼š\n- ãƒ–ãƒ©ã‚¦ã‚¶ã®æ›´æ–°ï¼ˆCtrl+F5ï¼‰\n- ç•°ãªã‚‹ãƒ–ãƒ©ã‚¦ã‚¶ã§ã®ã‚¢ã‚¯ã‚»ã‚¹\n- ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª")

def create_prediction_vs_actual_scatter(df, selected_predictions):
    """äºˆæ¸¬vså®Ÿç¸¾æ•£å¸ƒå›³ã‚’ä½œæˆï¼ˆâ‘¥å‡¡ä¾‹ä¿®æ­£ï¼‰"""
    
    # â‘¡ ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä¸­é …ç›®è¦‹å‡ºã—ã‚¹ã‚¿ã‚¤ãƒ«ã§è¡¨ç¤º
    st.markdown('<div class="step-title">äºˆæ¸¬å€¤ vs å®Ÿç¸¾å€¤æ•£å¸ƒå›³</div>', unsafe_allow_html=True)
    
    # â‘£ èª¬æ˜æ–‡è¿½åŠ 
    st.markdown(
        '<div class="step-annotation">å„åŒºåˆ†ã®äºˆæ¸¬ç²¾åº¦ã‚’å•†å“ã‚³ãƒ¼ãƒ‰å˜ä½ã§å¯è¦–åŒ–ã—ã€å®Ÿç¸¾å€¤ã«å¯¾ã™ã‚‹è¨ˆç”»å€¤ã®å¦¥å½“æ€§ã‚’ç¢ºèªã—ã¾ã™ï¼ˆç ´ç·šã¯å®Œå…¨ä¸€è‡´ãƒ©ã‚¤ãƒ³ã‚’ç¤ºã—ã¾ã™ï¼‰ã€‚</div>',
        unsafe_allow_html=True
    )
    
    try:
        # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
        if df.empty:
            st.warning("âš ï¸ è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
        fig = make_subplots(
            rows=1, 
            cols=len(selected_predictions),
            subplot_titles=[get_prediction_name(pred) for pred in selected_predictions]
        )
        
        # â‘¥ å‡¡ä¾‹ç”¨ã®åŒºåˆ†ã‚’æ•´ç†ï¼ˆã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆé †ï¼‰
        all_abc_classes = set()
        if 'Class_abc' in df.columns:
            all_abc_classes = set(df['Class_abc'].dropna().unique())
        
        sorted_abc_classes = sorted(list(all_abc_classes))
        
        for i, pred_col in enumerate(selected_predictions):
            try:
                # äºˆæ¸¬ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                if pred_col not in df.columns:
                    st.warning(f"âš ï¸ ã‚«ãƒ©ãƒ  '{pred_col}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                    continue
                
                # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ï¼šNaNã€Infå€¤ã‚’é™¤å»
                plot_data = df[['Actual', pred_col, 'P_code', 'Date'] + 
                              (['Class_abc'] if 'Class_abc' in df.columns else [])].copy()
                plot_data = plot_data.replace([np.inf, -np.inf], np.nan)
                plot_data = plot_data.dropna(subset=['Actual', pred_col])
                
                if plot_data.empty:
                    st.warning(f"âš ï¸ {get_prediction_name(pred_col)} ã®æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                    continue
                
                # è‰²åˆ†ã‘ç”¨ã®åˆ—ã‚’ä½œæˆï¼ˆABCåŒºåˆ†ãŒã‚ã‚Œã°ä½¿ç”¨ï¼‰
                if 'Class_abc' in df.columns:
                    color_col = 'Class_abc'
                    color_discrete_map = {k: v for k, v in UNIFIED_COLOR_PALETTE.items() 
                                        if k in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'Z']}
                    # â‘¡ å‡¡ä¾‹ã‚’ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆé †ã«è¡¨ç¤ºã™ã‚‹ãŸã‚ã®category_orders
                    category_orders = {color_col: sorted_abc_classes}
                else:
                    color_col = None
                    color_discrete_map = None
                    category_orders = None
                
                # æ•£å¸ƒå›³ä½œæˆï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
                scatter = px.scatter(
                    plot_data,
                    x='Actual',
                    y=pred_col,
                    color=color_col,
                    color_discrete_map=color_discrete_map,
                    category_orders=category_orders,
                    hover_data=['P_code', 'Date'],
                    title=f"{get_prediction_name(pred_col)} vs å®Ÿç¸¾"
                )
                
                # â‘¥ å‡¡ä¾‹ã®è¡¨ç¤ºé †ãƒ»ãƒ©ãƒ™ãƒ«ã®ä¿®æ­£
                added_legends = set()
                for trace in scatter.data:
                    if 'Class_abc' in df.columns and trace.name and trace.name in sorted_abc_classes:
                        legend_name = f"{trace.name}åŒºåˆ†"
                        trace.name = legend_name
                        if legend_name in added_legends or i > 0:
                            trace.showlegend = False
                        else:
                            added_legends.add(legend_name)
                    elif not trace.name:  # ç©ºã®åå‰ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåã‚’è¨­å®š
                        trace.name = "ãƒ‡ãƒ¼ã‚¿"
                        trace.showlegend = False
                    fig.add_trace(trace, row=1, col=i+1)
                
                # å®Œå…¨ä¸€è‡´ãƒ©ã‚¤ãƒ³ï¼ˆy=xï¼‰ã‚’è¿½åŠ 
                max_val = max(plot_data['Actual'].max(), plot_data[pred_col].max())
                min_val = min(plot_data['Actual'].min(), plot_data[pred_col].min())
                
                # min_val, max_valãŒæœ‰åŠ¹ãªå€¤ã‹ãƒã‚§ãƒƒã‚¯
                if pd.isna(min_val) or pd.isna(max_val) or min_val == max_val:
                    continue
                
                fig.add_trace(
                    go.Scatter(
                        x=[min_val, max_val], 
                        y=[min_val, max_val],
                        mode='lines',
                        line=dict(color='red', dash='dash'),
                        name='å®Œå…¨ä¸€è‡´ç·š',
                        showlegend=(i == 0)  # æœ€åˆã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã®ã¿å‡¡ä¾‹è¡¨ç¤º
                    ),
                    row=1, col=i+1
                )
                
            except Exception as sub_error:
                st.error(f"âŒ {get_prediction_name(pred_col)} ã®æ•£å¸ƒå›³ä½œæˆã§ã‚¨ãƒ©ãƒ¼: {str(sub_error)}")
                continue
        
        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
        fig.update_layout(
            height=600,
            showlegend=True
        )
        
        fig.update_xaxes(title_text="å®Ÿç¸¾å€¤")
        fig.update_yaxes(title_text="è¨ˆç”»å€¤")
        
        # ã‚°ãƒ©ãƒ•è¡¨ç¤ºï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
        st.plotly_chart(fig, use_container_width=True)
        
        # å‡¡ä¾‹ã«ã‚ˆã‚‹è¡¨ç¤ºåˆ‡æ›¿æ©Ÿèƒ½ã®å‘¨çŸ¥
        st.markdown(
            '<div class="step-annotation">ğŸ’¡ å‡¡ä¾‹é …ç›®ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€è©²å½“ã™ã‚‹åŒºåˆ†ã®è¡¨ç¤º/éè¡¨ç¤ºã‚’åˆ‡ã‚Šæ›¿ãˆã§ãã¾ã™ã€‚</div>',
            unsafe_allow_html=True
        )
        
    except Exception as e:
        st.error(f"âŒ æ•£å¸ƒå›³ã®ä½œæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.info("ğŸ’¡ ä»¥ä¸‹ã®æ–¹æ³•ã‚’ãŠè©¦ã—ãã ã•ã„ï¼š\n- ãƒ–ãƒ©ã‚¦ã‚¶ã®æ›´æ–°ï¼ˆCtrl+F5ï¼‰\n- ç•°ãªã‚‹ãƒ–ãƒ©ã‚¦ã‚¶ã§ã®ã‚¢ã‚¯ã‚»ã‚¹\n- ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª")

def calculate_abc_average_errors(df, selected_predictions):
    """ABCåŒºåˆ†åˆ¥ã®åŠ é‡å¹³å‡èª¤å·®ç‡ã‚’è¨ˆç®—ï¼ˆé›†è¨ˆæ–¹é‡æº–æ‹ ãƒ»å…¨åŒºåˆ†å¯¾å¿œï¼‰"""
    if 'Class_abc' not in df.columns:
        return {}
    
    abc_errors = {}
    
    for pred_col in selected_predictions:
        df_with_errors = calculate_error_rates(df, pred_col, 'Actual')
        
        # ABCåŒºåˆ†åˆ¥ã®åŠ é‡å¹³å‡èª¤å·®ç‡è¨ˆç®—ï¼ˆå…¨åŒºåˆ†å¯¾å¿œãƒ»æœªåŒºåˆ†å¯¾å¿œï¼‰
        abc_stats = {}
        # æœªåŒºåˆ†ï¼ˆNaNï¼‰ã‚‚å«ã‚ã¦å‡¦ç†
        df_with_errors['Class_abc'] = df_with_errors['Class_abc'].fillna('æœªåŒºåˆ†')
        unique_abc_classes = sorted(df_with_errors['Class_abc'].unique())
        
        for abc_class in unique_abc_classes:
            abc_data = df_with_errors[df_with_errors['Class_abc'] == abc_class]
            if not abc_data.empty and len(abc_data) > 0:
                # çµ¶å¯¾èª¤å·®ç‡ã®åŠ é‡å¹³å‡ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿å¯¾è±¡ï¼‰
                absolute_weighted_avg = calculate_weighted_average_error_rate(
                    abc_data, 'absolute_error_rate', 'Actual'
                )
                
                # æ­£ã®èª¤å·®ç‡ã®åŠ é‡å¹³å‡ï¼ˆpositive_error_rateåˆ—ã‚’ä½¿ç”¨ã€èª¤å·®ç‡0%ã‚’å«ã‚€ï¼‰
                positive_weighted_avg = calculate_weighted_average_error_rate(
                    abc_data, 'positive_error_rate', 'Actual'
                )
                
                # è² ã®èª¤å·®ç‡ã®åŠ é‡å¹³å‡ï¼ˆnegative_error_rateåˆ—ã‚’ä½¿ç”¨ã€èª¤å·®ç‡0%ã‚’é™¤å¤–ï¼‰
                negative_weighted_avg = calculate_weighted_average_error_rate(
                    abc_data, 'negative_error_rate', 'Actual'
                )
                
                # NaNã®å ´åˆã¯0.0ã«è¨­å®š
                if pd.isna(positive_weighted_avg):
                    positive_weighted_avg = 0.0
                if pd.isna(negative_weighted_avg):
                    negative_weighted_avg = 0.0
                
                abc_stats[abc_class] = {
                    'count': len(abc_data),
                    'actual_sum': abc_data['Actual'].sum(),
                    'absolute_error_rate': absolute_weighted_avg,
                    'positive_error_rate': positive_weighted_avg,
                    'negative_error_rate': negative_weighted_avg
                }
        
        abc_errors[pred_col] = abc_stats
    
    return abc_errors

def display_abc_average_table(abc_errors, filtered_df):
    """â‘¡ ABCåŒºåˆ†åˆ¥åŠ é‡å¹³å‡èª¤å·®ç‡ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä¸­é …ç›®è¦‹å‡ºã—ã‚¹ã‚¿ã‚¤ãƒ«ã§è¡¨ç¤º"""
    if not abc_errors:
        st.info("ABCåŒºåˆ†ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # â‘¡ ä¸­é …ç›®è¦‹å‡ºã—ï¼ˆSTEPè¦‹å‡ºã—ã‚¹ã‚¿ã‚¤ãƒ«çµ±ä¸€ï¼‰
    st.markdown('<div class="step-title">ABCåŒºåˆ†åˆ¥ åŠ é‡å¹³å‡èª¤å·®ç‡</div>', unsafe_allow_html=True)
    st.markdown(
        '<div class="step-annotation">ABCåŒºåˆ†åˆ¥ã®åŠ é‡å¹³å‡èª¤å·®ç‡ã¨ã—ã¦ã€ã€Œçµ¶å¯¾èª¤å·®ç‡ã€ã€ã€Œè² ã®èª¤å·®ç‡ï¼ˆï¼æ¬ å“ãƒªã‚¹ã‚¯ï¼‰ã€ã€ã€Œæ­£ã®èª¤å·®ç‡ï¼ˆï¼éå‰°åœ¨åº«ãƒªã‚¹ã‚¯ï¼‰ã€ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚</div>',
        unsafe_allow_html=True
    )
    
    # å…¨ã¦ã®äºˆæ¸¬ã‚«ãƒ©ãƒ ã‹ã‚‰å…¨ã¦ã®ABCåŒºåˆ†ã‚’å–å¾—
    all_abc_classes = set()
    for pred_col, abc_stats in abc_errors.items():
        all_abc_classes.update(abc_stats.keys())
    
    if not all_abc_classes:
        st.info("ABCåŒºåˆ†ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # ABCåŒºåˆ†ã‚’ã‚½ãƒ¼ãƒˆï¼ˆA, B, C, D...ã®é †ï¼‰
    sorted_abc_classes = sorted(list(all_abc_classes))
    
    # 2æ®µãƒ˜ãƒƒãƒ€ãƒ¼æ§‹é€ ã®MultiIndexä½œæˆï¼ˆ1è¡Œç›®éè¡¨ç¤ºå¯¾å¿œï¼‰
    columns_tuples = [
        ('', 'åŒºåˆ†'),
        ('', 'ä»¶æ•°'),
        ('', 'å®Ÿç¸¾åˆè¨ˆ')
    ]
    
    for error_type in ['çµ¶å¯¾èª¤å·®ç‡', 'è² ã®èª¤å·®ç‡', 'æ­£ã®èª¤å·®ç‡']:
        for pred_col in sorted(abc_errors.keys()):
            pred_name = get_prediction_name(pred_col)
            columns_tuples.append((error_type, pred_name))
    
    multi_columns = pd.MultiIndex.from_tuples(columns_tuples)
    
    # ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    table_data = []
    total_counts = {}
    total_actual_sums = {}
    
    # äºˆæ¸¬ã‚«ãƒ©ãƒ åˆ¥ã®åˆè¨ˆã‚’è¨ˆç®—
    for pred_col in abc_errors.keys():
        total_counts[pred_col] = sum(stats['count'] for stats in abc_errors[pred_col].values())
        total_actual_sums[pred_col] = sum(stats['actual_sum'] for stats in abc_errors[pred_col].values())
    
    # ABCåŒºåˆ†åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    for abc_class in sorted_abc_classes:
        row_data = [f'{abc_class}åŒºåˆ†']
        
        # ä»¶æ•°ã¨å®Ÿç¸¾åˆè¨ˆã®è¨ˆç®—ï¼ˆå…¨äºˆæ¸¬ã®å¹³å‡ã¾ãŸã¯åˆè¨ˆï¼‰
        total_count = 0
        total_actual = 0
        
        for pred_col in sorted(abc_errors.keys()):
            if abc_class in abc_errors[pred_col]:
                stats = abc_errors[pred_col][abc_class]
                total_count = max(total_count, stats['count'])  # æœ€å¤§å€¤ã‚’ä½¿ç”¨ï¼ˆåŒã˜åŒºåˆ†ãªã®ã§ï¼‰
                total_actual = max(total_actual, stats['actual_sum'])  # æœ€å¤§å€¤ã‚’ä½¿ç”¨
        
        # ä»¶æ•°ã¨å®Ÿç¸¾åˆè¨ˆã‚’æ–‡å­—åˆ—å½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        row_data.extend([f"{total_count:,}", f"{total_actual:,.0f}"])
        
        # å„èª¤å·®ç‡ã®å€¤ã‚’è¿½åŠ ï¼ˆçµ¶å¯¾ã€è² ã€æ­£ã®é †ï¼‰
        for error_type in ['absolute_error_rate', 'negative_error_rate', 'positive_error_rate']:
            for pred_col in sorted(abc_errors.keys()):
                if abc_class in abc_errors[pred_col]:
                    error_rate = abc_errors[pred_col][abc_class][error_type]
                    if error_type == 'positive_error_rate':
                        # æ­£ã®èª¤å·®ç‡ã«ã¯+è¨˜å·ã‚’ä»˜ã‘ã‚‹
                        formatted_rate = f"ï¼‹{error_rate:.1%}"
                    elif error_type == 'negative_error_rate':
                        # è² ã®èª¤å·®ç‡ã«ã¯â–²è¨˜å·ã‚’ä»˜ã‘ã‚‹
                        formatted_rate = f"â–²{abs(error_rate):.1%}"
                    else:
                        formatted_rate = f"{error_rate:.1%}"
                    row_data.append(formatted_rate)
                else:
                    # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆ
                    if error_type == 'positive_error_rate':
                        row_data.append("ï¼‹0.0%")
                    elif error_type == 'negative_error_rate':
                        row_data.append("â–²0.0%")
                    else:
                        row_data.append("0.0%")
        
        table_data.append(row_data)
    
    # åˆè¨ˆè¡Œã®ä½œæˆ
    total_row_data = ['åˆè¨ˆ']
    
    # ã‚ˆã‚Šæ­£ç¢ºãªåˆè¨ˆè¨ˆç®—ï¼ˆæœ€åˆã®äºˆæ¸¬ã‚«ãƒ©ãƒ ã‹ã‚‰å…¨ãƒ‡ãƒ¼ã‚¿ã®åˆè¨ˆã‚’è¨ˆç®—ï¼‰
    if abc_errors:
        first_pred = list(abc_errors.keys())[0]
        grand_total_count = sum(stats['count'] for stats in abc_errors[first_pred].values())
        grand_total_actual = sum(stats['actual_sum'] for stats in abc_errors[first_pred].values())
    else:
        grand_total_count = 0
        grand_total_actual = 0
    
    # åˆè¨ˆè¡Œã‚‚æ–‡å­—åˆ—å½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    total_row_data.extend([f"{grand_total_count:,}", f"{grand_total_actual:,.0f}"])
    
    # å„èª¤å·®ç‡ã®å…¨ä½“åŠ é‡å¹³å‡ã‚’è¨ˆç®—ï¼ˆé›†è¨ˆæ–¹é‡æº–æ‹ ï¼‰
    for error_type in ['absolute_error_rate', 'negative_error_rate', 'positive_error_rate']:
        for pred_col in sorted(abc_errors.keys()):
            # å…¨ä½“ã®åŠ é‡å¹³å‡ã‚’è¨ˆç®—ï¼ˆå°‚ç”¨ã®èª¤å·®ç‡åˆ—ã‚’ä½¿ç”¨ï¼‰
            df_with_errors = calculate_error_rates(filtered_df, pred_col, 'Actual')
            
            if error_type == 'positive_error_rate':
                # positive_error_rateåˆ—ã‚’ä½¿ç”¨ï¼ˆèª¤å·®ç‡0%ã‚’å«ã‚€ï¼‰
                overall_rate = calculate_weighted_average_error_rate(df_with_errors, 'positive_error_rate', 'Actual')
                if pd.isna(overall_rate):
                    overall_rate = 0.0
                formatted_rate = f"ï¼‹{overall_rate:.1%}"
                    
            elif error_type == 'negative_error_rate':
                # negative_error_rateåˆ—ã‚’ä½¿ç”¨ï¼ˆèª¤å·®ç‡0%ã‚’é™¤å¤–ï¼‰
                overall_rate = calculate_weighted_average_error_rate(df_with_errors, 'negative_error_rate', 'Actual')
                if pd.isna(overall_rate):
                    overall_rate = 0.0
                formatted_rate = f"â–²{abs(overall_rate):.1%}"
                    
            else:  # absolute_error_rate
                # absolute_error_rateåˆ—ã‚’ä½¿ç”¨ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿å¯¾è±¡ï¼‰
                overall_rate = calculate_weighted_average_error_rate(df_with_errors, 'absolute_error_rate', 'Actual')
                if pd.isna(overall_rate):
                    overall_rate = 0.0
                formatted_rate = f"{overall_rate:.1%}"
            
            total_row_data.append(formatted_rate)
    
    table_data.append(total_row_data)
    
    # DataFrameä½œæˆ
    df_table = pd.DataFrame(table_data, columns=multi_columns)
    
    # ã‚«ã‚¹ã‚¿ãƒ CSS for èª¿æ•´æ¸ˆã¿ã‚«ãƒ©ãƒ å¹…ï¼ˆ1è¡Œç›®ãƒ˜ãƒƒãƒ€ãƒ¼éè¡¨ç¤ºï¼‰
    table_css = """
    <style>
    .stDataFrame > div {
        width: 100%;
    }
    .stDataFrame table {
        width: 100% !important;
    }
    .stDataFrame th, .stDataFrame td {
        text-align: center !important;
    }
    /* åŒºåˆ†åˆ—ï¼š8% */
    .stDataFrame th:nth-child(1), .stDataFrame td:nth-child(1) {
        width: 8% !important;
        min-width: 60px !important;
    }
    /* ä»¶æ•°åˆ—ï¼š8% */
    .stDataFrame th:nth-child(2), .stDataFrame td:nth-child(2) {
        width: 8% !important;
        min-width: 60px !important;
    }
    /* å®Ÿç¸¾åˆè¨ˆåˆ—ï¼š8% */
    .stDataFrame th:nth-child(3), .stDataFrame td:nth-child(3) {
        width: 8% !important;
        min-width: 60px !important;
    }
    /* æ®‹ã‚Š6åˆ—ï¼ˆè¨ˆç”»å€¤01ã€è¨ˆç”»å€¤02ã€AIäºˆæ¸¬å€¤ã®ãã‚Œãã‚Œ3ç¨®é¡ï¼‰ï¼šå„12.67% */
    .stDataFrame th:nth-child(n+4), .stDataFrame td:nth-child(n+4) {
        width: 12.67% !important;
        min-width: 80px !important;
    }
    /* 1è¡Œç›®ã®ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆMultiIndexã®æœ€ä¸Šä½ãƒ¬ãƒ™ãƒ«ï¼‰ã‚’éè¡¨ç¤º */
    .stDataFrame thead tr:first-child {
        display: none;
    }
    /* å·¦å´3åˆ—ã®1è¡Œç›®ãƒ˜ãƒƒãƒ€ãƒ¼ã®å¢ƒç•Œç·šã‚‚éè¡¨ç¤º */
    .stDataFrame thead tr:first-child th:nth-child(1),
    .stDataFrame thead tr:first-child th:nth-child(2),
    .stDataFrame thead tr:first-child th:nth-child(3) {
        border-bottom: none !important;
    }
    </style>
    """
    st.markdown(table_css, unsafe_allow_html=True)
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
    st.dataframe(
        df_table,
        use_container_width=True,
        hide_index=True
    )
    
    # æ³¨é‡ˆã®é…ç½®ã¨ã‚¹ã‚¿ã‚¤ãƒ«èª¿æ•´ï¼ˆè¡¨ã®ä¸‹éƒ¨ã«ç§»å‹•ã€UI/UXã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³æº–æ‹ ï¼‰
    st.markdown("""
    <div class="step-annotation">
    â€» èª¤å·®ç‡ã¯å®Ÿç¸¾å€¤ã§é‡ã¿ã¥ã‘ã—ãŸåŠ é‡å¹³å‡å€¤ã§ã™ã€‚<br>
    â€» é›†è¨ˆæ–¹é‡ï¼šèª¤å·®ç‡0%ï¼ˆå®Œå…¨ä¸€è‡´ï¼‰ã¯ã€Œçµ¶å¯¾èª¤å·®ç‡ã€ã¨ã€Œæ­£ã®èª¤å·®ç‡ã€ã®ã¿ã«ã‚«ã‚¦ãƒ³ãƒˆã•ã‚Œã€ã€Œè² ã®èª¤å·®ç‡ã€ã‹ã‚‰ã¯é™¤å¤–ã•ã‚Œã¦ã„ã¾ã™ã€‚<br>
    â€» è² ã®èª¤å·®ç‡ã¯ã€Œâ–²ã€‡.ã€‡ï¼…ã€ã€æ­£ã®èª¤å·®ç‡ã¯ã€Œï¼‹ã€‡.ã€‡ï¼…ã€ã§è¡¨è¨˜ã—ã€ã™ã¹ã¦å°æ•°ç¬¬1ä½ã§çµ±ä¸€ã—ã¦ã„ã¾ã™ã€‚
    </div>
    """, unsafe_allow_html=True)

 