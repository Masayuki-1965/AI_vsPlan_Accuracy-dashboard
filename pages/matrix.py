import streamlit as st
import pandas as pd
import numpy as np
from utils.error_calculator import (
    calculate_error_rates, 
    create_error_matrix, 
    compare_prediction_accuracy,
    calculate_weighted_average_error_rate,
    categorize_error_rates
)

def show():
    """èª¤å·®ç‡è©•ä¾¡ãƒãƒˆãƒªã‚¯ã‚¹ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º"""
    st.header("ğŸ“Š èª¤å·®ç‡è©•ä¾¡ãƒãƒˆãƒªã‚¯ã‚¹")
    
    # ãƒ‡ãƒ¼ã‚¿ç¢ºèª
    if st.session_state.data is None:
        st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        return
    
    df = st.session_state.data
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    filter_settings = create_filter_ui(df)
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filtered_df = apply_advanced_filters(df, filter_settings)
    
    if filtered_df.empty:
        st.warning("âš ï¸ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    st.info(f"ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(filtered_df)}ä»¶")
    
    # èª¤å·®ç‡ãƒãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
    display_error_rate_matrix(filtered_df, filter_settings)
    
    # åŸºæœ¬çµ±è¨ˆæƒ…å ±è¡¨ç¤º
    display_basic_statistics(filtered_df, filter_settings)

def create_filter_ui(df):
    """æ”¹å–„ã•ã‚ŒãŸãƒ•ã‚£ãƒ«ã‚¿ãƒ¼UIã‚’ä½œæˆ"""
    filter_settings = {}
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        # èª¤å·®ç‡ã‚¿ã‚¤ãƒ—ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        error_types = {
            'çµ¶å¯¾èª¤å·®ç‡': 'absolute',
            'æ­£ã®èª¤å·®ç‡': 'positive', 
            'è² ã®èª¤å·®ç‡': 'negative'
        }
        selected_error_type = st.selectbox(
            "èª¤å·®ç‡ã‚¿ã‚¤ãƒ—",
            list(error_types.keys()),
            help="çµ¶å¯¾: |è¨ˆç”»-å®Ÿç¸¾|Ã·è¨ˆç”», æ­£: è¨ˆç”»>å®Ÿç¸¾(æ»ç•™), è² : è¨ˆç”»<å®Ÿç¸¾(æ¬ å“)"
        )
        filter_settings['error_type'] = error_types[selected_error_type]
        
    with col2:
        # è¨ˆç”»å€¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        plan_options = ['AIäºˆæ¸¬ vs è¨ˆç”»01']
        if 'Plan_02' in df.columns:
            plan_options.append('AIäºˆæ¸¬ vs è¨ˆç”»02')
        
        selected_comparison = st.selectbox("æ¯”è¼ƒå¯¾è±¡", plan_options)
        filter_settings['plan_column'] = 'Plan_01' if 'è¨ˆç”»01' in selected_comparison else 'Plan_02'
        
    with col3:
        # ABCåŒºåˆ†ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        if 'Class_abc' in df.columns:
            abc_values = sorted(df['Class_abc'].dropna().unique().tolist())
            default_abc = ['A', 'B', 'C'] if all(x in abc_values for x in ['A', 'B', 'C']) else abc_values[:3]
            
            selected_abc = st.multiselect(
                "ABCåŒºåˆ†è¡¨ç¤º",
                abc_values,
                default=default_abc,
                help="æœ€å¤§3ã¤ã¾ã§é¸æŠå¯èƒ½"
            )
            filter_settings['abc_categories'] = selected_abc[:3]  # æœ€å¤§3ã¤ã¾ã§
        else:
            filter_settings['abc_categories'] = []
    
    with col4:
        # æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        if 'Date' in df.columns:
            date_options = ['å…¨æœŸé–“'] + sorted(df['Date'].dropna().unique().tolist())
            selected_date = st.selectbox("æœŸé–“", date_options)
            filter_settings['date'] = None if selected_date == 'å…¨æœŸé–“' else selected_date
        else:
            filter_settings['date'] = None
    
    return filter_settings

def apply_advanced_filters(df, filter_settings):
    """æ”¹è‰¯ã•ã‚ŒãŸãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨"""
    filtered_df = df.copy()
    
    # æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    if filter_settings['date'] and 'Date' in df.columns:
        filtered_df = filtered_df[filtered_df['Date'] == filter_settings['date']]
    
    return filtered_df

def get_prediction_name(pred_type):
    """äºˆæ¸¬ã‚¿ã‚¤ãƒ—ã®è¡¨ç¤ºåã‚’å–å¾—"""
    name_mapping = {
        'AI_pred': 'AIäºˆæ¸¬',
        'Plan_01': 'è¨ˆç”»01',
        'Plan_02': 'è¨ˆç”»02'
    }
    return name_mapping.get(pred_type, pred_type)

def display_error_rate_matrix(df, filter_settings):
    """è¦æ±‚ä»•æ§˜ã«åŸºã¥ãèª¤å·®ç‡ãƒãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º"""
    st.subheader("ğŸ“Š èª¤å·®ç‡è©•ä¾¡ãƒãƒˆãƒªã‚¯ã‚¹")
    
    # è¨ˆç”»å€¤ã¨AIäºˆæ¸¬ã®èª¤å·®ç‡è¨ˆç®—
    plan_col = filter_settings['plan_column']
    error_type = filter_settings['error_type']
    abc_categories = filter_settings['abc_categories']
    
    # AIäºˆæ¸¬ã¨è¨ˆç”»å€¤ã®èª¤å·®ç‡è¨ˆç®—
    ai_errors = calculate_error_rates(df, 'AI_pred', 'Actual')
    plan_errors = calculate_error_rates(df, plan_col, 'Actual')
    
    # ãƒãƒˆãƒªã‚¯ã‚¹ä½œæˆ
    ai_matrix = create_advanced_matrix(ai_errors, 'AI_pred', error_type, abc_categories)
    plan_matrix = create_advanced_matrix(plan_errors, plan_col, error_type, abc_categories)
    
    # ãƒãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
    display_combined_matrix(ai_matrix, plan_matrix, error_type, abc_categories)

def create_advanced_matrix(df, pred_col, error_type, abc_categories):
    """é«˜åº¦ãªãƒãƒˆãƒªã‚¯ã‚¹ä½œæˆ"""
    # èª¤å·®ç‡ã‚«ãƒ©ãƒ é¸æŠ
    if error_type == 'absolute':
        error_col = 'absolute_error_rate'
        error_name = 'çµ¶å¯¾èª¤å·®ç‡'
    elif error_type == 'positive':
        error_col = 'positive_error_rate'
        error_name = 'æ­£ã®èª¤å·®ç‡'
    else:  # negative
        error_col = 'negative_error_rate'
        error_name = 'è² ã®èª¤å·®ç‡'
    
    # èª¤å·®ç‡åŒºåˆ†è¿½åŠ 
    df_with_category = df.copy()
    df_with_category['error_category'] = categorize_error_rates(df, error_col)
    
    # åˆè¨ˆãƒãƒˆãƒªã‚¯ã‚¹
    total_matrix = df_with_category.groupby('error_category').agg({
        'P_code': 'count',
        error_col: lambda x: calculate_weighted_average_error_rate(
            df_with_category.loc[x.index], error_col, 'Actual'
        )
    }).rename(columns={'P_code': 'count', error_col: 'weighted_avg_error'})
    
    # ABCåŒºåˆ†åˆ¥ãƒãƒˆãƒªã‚¯ã‚¹
    abc_matrices = {}
    if 'Class_abc' in df.columns and abc_categories:
        for abc in abc_categories:
            abc_data = df_with_category[df_with_category['Class_abc'] == abc]
            if not abc_data.empty:
                abc_matrix = abc_data.groupby('error_category').agg({
                    'P_code': 'count',
                    error_col: lambda x: calculate_weighted_average_error_rate(
                        abc_data.loc[x.index], error_col, 'Actual'
                    ) if len(x) > 0 else np.nan
                }).rename(columns={'P_code': 'count', error_col: 'weighted_avg_error'})
                abc_matrices[abc] = abc_matrix
    
    return {
        'total': total_matrix,
        'abc': abc_matrices,
        'error_type': error_name
    }

def display_combined_matrix(ai_matrix, plan_matrix, error_type, abc_categories):
    """çµåˆãƒãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º"""
    # èª¤å·®ç‡ã‚«ãƒ†ã‚´ãƒªãƒ¼
    error_categories = ['0-10%', '10-20%', '20-30%', '30-50%', '50-100%', '100%è¶…']
    
    # è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
    matrix_data = []
    
    for category in error_categories:
        row = {'èª¤å·®ç‡å¸¯': category}
        
        # åˆè¨ˆï¼ˆAIäºˆæ¸¬ï¼è¨ˆç”»ï¼‰
        ai_count = ai_matrix['total'].loc[category, 'count'] if category in ai_matrix['total'].index else 0
        plan_count = plan_matrix['total'].loc[category, 'count'] if category in plan_matrix['total'].index else 0
        row['åˆè¨ˆ_AIäºˆæ¸¬'] = ai_count
        row['åˆè¨ˆ_è¨ˆç”»'] = plan_count
        
        # ABCåŒºåˆ†åˆ¥
        for abc in abc_categories:
            if abc in ai_matrix['abc']:
                ai_abc_count = ai_matrix['abc'][abc].loc[category, 'count'] if category in ai_matrix['abc'][abc].index else 0
            else:
                ai_abc_count = 0
                
            if abc in plan_matrix['abc']:
                plan_abc_count = plan_matrix['abc'][abc].loc[category, 'count'] if category in plan_matrix['abc'][abc].index else 0
            else:
                plan_abc_count = 0
                
            row[f'{abc}åŒºåˆ†_AIäºˆæ¸¬'] = ai_abc_count
            row[f'{abc}åŒºåˆ†_è¨ˆç”»'] = plan_abc_count
        
        matrix_data.append(row)
    
    # åŠ é‡å¹³å‡èª¤å·®ç‡è¡Œã‚’è¿½åŠ 
    weighted_avg_row = {'èª¤å·®ç‡å¸¯': 'åŠ é‡å¹³å‡'}
    
    # åˆè¨ˆã®åŠ é‡å¹³å‡
    ai_total_avg = calculate_overall_weighted_average(ai_matrix['total'])
    plan_total_avg = calculate_overall_weighted_average(plan_matrix['total'])
    weighted_avg_row['åˆè¨ˆ_AIäºˆæ¸¬'] = f"{ai_total_avg:.0%}" if not np.isnan(ai_total_avg) else "N/A"
    weighted_avg_row['åˆè¨ˆ_è¨ˆç”»'] = f"{plan_total_avg:.0%}" if not np.isnan(plan_total_avg) else "N/A"
    
    # ABCåŒºåˆ†åˆ¥ã®åŠ é‡å¹³å‡
    for abc in abc_categories:
        if abc in ai_matrix['abc']:
            ai_abc_avg = calculate_overall_weighted_average(ai_matrix['abc'][abc])
            weighted_avg_row[f'{abc}åŒºåˆ†_AIäºˆæ¸¬'] = f"{ai_abc_avg:.0%}" if not np.isnan(ai_abc_avg) else "N/A"
        else:
            weighted_avg_row[f'{abc}åŒºåˆ†_AIäºˆæ¸¬'] = "N/A"
            
        if abc in plan_matrix['abc']:
            plan_abc_avg = calculate_overall_weighted_average(plan_matrix['abc'][abc])
            weighted_avg_row[f'{abc}åŒºåˆ†_è¨ˆç”»'] = f"{plan_abc_avg:.0%}" if not np.isnan(plan_abc_avg) else "N/A"
        else:
            weighted_avg_row[f'{abc}åŒºåˆ†_è¨ˆç”»'] = "N/A"
    
    matrix_data.append(weighted_avg_row)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆãƒ»è¡¨ç¤º
    matrix_df = pd.DataFrame(matrix_data)
    
    # ã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨
    def highlight_weighted_avg(row):
        return ['background-color: #f0f0f0' if row.name == len(matrix_df) - 1 else '' for _ in row]
    
    styled_df = matrix_df.style.apply(highlight_weighted_avg, axis=1)
    
    st.dataframe(styled_df, use_container_width=True)
    
def calculate_overall_weighted_average(matrix):
    """å…¨ä½“åŠ é‡å¹³å‡èª¤å·®ç‡è¨ˆç®—"""
    if matrix.empty:
        return np.nan
    
    # å„ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®åŠ é‡å¹³å‡èª¤å·®ç‡ã¨ä»¶æ•°ã‚’ç”¨ã„ã¦å…¨ä½“å¹³å‡ã‚’è¨ˆç®—
    total_weighted_sum = 0
    total_count = 0
    
    for _, row in matrix.iterrows():
        if not np.isnan(row['weighted_avg_error']) and row['count'] > 0:
            total_weighted_sum += row['weighted_avg_error'] * row['count']
            total_count += row['count']
    
    return total_weighted_sum / total_count if total_count > 0 else np.nan

def display_basic_statistics(df, filter_settings):
    """åŸºæœ¬çµ±è¨ˆæƒ…å ±ã‚’çµ±ä¸€å½¢å¼ã§è¡¨ç¤º"""
    st.subheader("ğŸ“ˆ åŸºæœ¬çµ±è¨ˆæƒ…å ±")
    
    plan_col = filter_settings['plan_column']
    
    # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
    stats_data = {}
    
    # AIäºˆæ¸¬å€¤çµ±è¨ˆ
    ai_stats = df['AI_pred'].describe()
    stats_data['AIäºˆæ¸¬å€¤'] = ai_stats
    
    # è¨ˆç”»å€¤çµ±è¨ˆ
    plan_name = 'è¨ˆç”»01' if plan_col == 'Plan_01' else 'è¨ˆç”»02'
    plan_stats = df[plan_col].describe()
    stats_data[plan_name] = plan_stats
    
    # å®Ÿç¸¾å€¤çµ±è¨ˆ
    actual_stats = df['Actual'].describe()
    stats_data['å®Ÿç¸¾å€¤'] = actual_stats
    
    # çµ±è¨ˆè¡¨ä½œæˆ
    stats_df = pd.DataFrame(stats_data)
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åã‚’æ—¥æœ¬èªã«å¤‰æ›´
    index_mapping = {
        'count': 'ä»¶æ•°',
        'mean': 'å¹³å‡',
        'std': 'æ¨™æº–åå·®',
        'min': 'æœ€å°å€¤',
        '25%': '25%ç‚¹',
        '50%': 'ä¸­å¤®å€¤',
        '75%': '75%ç‚¹',
        'max': 'æœ€å¤§å€¤'
    }
    
    stats_df.index = [index_mapping.get(idx, idx) for idx in stats_df.index]
    
    # æ•°å€¤ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé©ç”¨
    formatted_df = stats_df.style.format({
        'AIäºˆæ¸¬å€¤': '{:.1f}',
        plan_name: '{:.1f}',
        'å®Ÿç¸¾å€¤': '{:.1f}'
    })
    
    st.dataframe(formatted_df, use_container_width=True)
    
    # ç›¸é–¢åˆ†æ
    st.subheader("ğŸ”— ç›¸é–¢åˆ†æ")
    col1, col2 = st.columns(2)
    
    with col1:
        ai_actual_corr = df['AI_pred'].corr(df['Actual'])
        st.metric(
            f"AIäºˆæ¸¬ vs å®Ÿç¸¾ ç›¸é–¢ä¿‚æ•°",
            f"{ai_actual_corr:.3f}",
            help="1ã«è¿‘ã„ã»ã©æ­£ã®ç›¸é–¢ãŒå¼·ã„"
        )
    
    with col2:
        plan_actual_corr = df[plan_col].corr(df['Actual'])
        st.metric(
            f"{plan_name} vs å®Ÿç¸¾ ç›¸é–¢ä¿‚æ•°",
            f"{plan_actual_corr:.3f}",
            help="1ã«è¿‘ã„ã»ã©æ­£ã®ç›¸é–¢ãŒå¼·ã„"
        ) 