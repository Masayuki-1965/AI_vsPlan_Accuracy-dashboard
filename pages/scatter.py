import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from utils.error_calculator import calculate_error_rates, calculate_weighted_average_error_rate
from config.constants import UNIFIED_COLOR_PALETTE, PREDICTION_TYPE_NAMES

def show():
    """æ•£å¸ƒå›³åˆ†æãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º"""
    st.header("ğŸ“ˆ æ•£å¸ƒå›³åˆ†æ")
    
    # ãƒ‡ãƒ¼ã‚¿ç¢ºèª
    if st.session_state.data is None:
        st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        return
    
    df = st.session_state.data
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®šï¼ˆæœŸé–“ã®ã¿ï¼‰
    st.subheader("ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    filtered_df = apply_filters(df)
    
    if filtered_df.empty:
        st.warning("âš ï¸ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    st.info(f"ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(filtered_df)}ä»¶")
    
    # ABCåŒºåˆ†åˆ¥åŠ é‡å¹³å‡èª¤å·®ç‡è¡¨ã‚’å¸¸æ™‚è¡¨ç¤º
    if 'Class_abc' in filtered_df.columns:
        prediction_columns = ['AI_pred', 'Plan_01']
        if 'Plan_02' in df.columns:
            prediction_columns.append('Plan_02')
        
        abc_avg_errors = calculate_abc_average_errors(filtered_df, prediction_columns)
        display_abc_average_table(abc_avg_errors, filtered_df)
    
    # æ•£å¸ƒå›³è¡¨ç¤ºè¨­å®š
    st.subheader("âš™ï¸ è¡¨ç¤ºè¨­å®š")
    col1, col2 = st.columns(2)
    
    with col1:
        prediction_columns = ['AI_pred', 'Plan_01']
        if 'Plan_02' in df.columns:
            prediction_columns.append('Plan_02')
        
        selected_predictions = st.multiselect(
            "è¡¨ç¤ºã™ã‚‹äºˆæ¸¬ãƒ»è¨ˆç”»",
            prediction_columns,
            default=prediction_columns,
            format_func=get_prediction_name
        )
    
    with col2:
        plot_type = st.selectbox(
            "ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒ—",
            ['äºˆæ¸¬å€¤ vs å®Ÿç¸¾å€¤æ•£å¸ƒå›³', 'èª¤å·®ç‡æ•£å¸ƒå›³ï¼ˆæ¨ªè»¸ï¼šèª¤å·®ç‡ ï¼ ç¸¦è»¸ï¼šè¨ˆç”»å€¤ï¼‰']
        )
    
    if not selected_predictions:
        st.warning("âš ï¸ è¡¨ç¤ºã™ã‚‹äºˆæ¸¬ãƒ»è¨ˆç”»ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return
    
    # æ•£å¸ƒå›³ä½œæˆãƒ»è¡¨ç¤º
    if plot_type == 'èª¤å·®ç‡æ•£å¸ƒå›³ï¼ˆæ¨ªè»¸ï¼šèª¤å·®ç‡ ï¼ ç¸¦è»¸ï¼šè¨ˆç”»å€¤ï¼‰':
        create_error_rate_scatter(filtered_df, selected_predictions)
    else:
        create_prediction_vs_actual_scatter(filtered_df, selected_predictions)

def apply_filters(df):
    """ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®šUIã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆæœŸé–“ã®ã¿ï¼‰"""
    # æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®ã¿ã«å¤‰æ›´
    if 'Date' in df.columns:
        date_options = ['å…¨æœŸé–“'] + sorted(df['Date'].dropna().unique().tolist())
        selected_date = st.selectbox("æœŸé–“", date_options)
    else:
        selected_date = 'å…¨æœŸé–“'
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filtered_df = df.copy()
    
    if selected_date != 'å…¨æœŸé–“' and 'Date' in df.columns:
        filtered_df = filtered_df[filtered_df['Date'] == selected_date]
    
    return filtered_df

def get_prediction_name(pred_type):
    """äºˆæ¸¬ã‚¿ã‚¤ãƒ—ã®è¡¨ç¤ºåã‚’å–å¾—"""
    return PREDICTION_TYPE_NAMES.get(pred_type, pred_type)

def create_error_rate_scatter(df, selected_predictions):
    """èª¤å·®ç‡æ•£å¸ƒå›³ã‚’ä½œæˆ"""
    
    # æ¨ªè»¸ã‚¹ã‚±ãƒ¼ãƒ«è¨­å®šUI
    st.subheader("âš™ï¸ æ¨ªè»¸ã‚¹ã‚±ãƒ¼ãƒ«è¨­å®š")
    col1, col2 = st.columns(2)
    
    with col1:
        x_min = st.number_input(
            "æ¨ªè»¸æœ€å°å€¤ (%)",
            value=-100,
            step=10,
            format="%d"
        )
    
    with col2:
        x_max = st.number_input(
            "æ¨ªè»¸æœ€å¤§å€¤ (%)",
            value=200,
            step=10,
            format="%d"
        )
    
    # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã‚’å°æ•°ã«å¤‰æ›
    x_min_decimal = x_min / 100
    x_max_decimal = x_max / 100
    
    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
    fig = make_subplots(
        rows=1, 
        cols=len(selected_predictions),
        subplot_titles=[get_prediction_name(pred) for pred in selected_predictions]
    )

    # å„ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã®ç¸¦è»¸ã®æœ€å°å€¤ãƒ»æœ€å¤§å€¤ã‚’çµ±ä¸€ã™ã‚‹ãŸã‚ã«äº‹å‰è¨ˆç®—
    all_y_values = []
    
    for i, pred_col in enumerate(selected_predictions):
        # èª¤å·®ç‡è¨ˆç®—
        df_with_errors = calculate_error_rates(df, pred_col, 'Actual')
        
        # è‰²åˆ†ã‘ç”¨ã®åˆ—ã‚’ä½œæˆï¼ˆABCåŒºåˆ†ãŒã‚ã‚Œã°ä½¿ç”¨ï¼‰
        if 'Class_abc' in df.columns:
            color_col = 'Class_abc'
            # ABCåŒºåˆ†ã‚«ãƒ©ãƒ¼ã‚’çµ±ä¸€ãƒ‘ãƒ¬ãƒƒãƒˆã‹ã‚‰å–å¾—
            color_discrete_map = {k: v for k, v in UNIFIED_COLOR_PALETTE.items() 
                                if k in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'Z']}
        else:
            color_col = None
            color_discrete_map = None
        
        # å®Ÿç¸¾ãŒã‚¼ãƒ­ã®å ´åˆã‚’é™¤å¤–ï¼ˆè¨ˆç®—ä¸èƒ½ï¼‰
        valid_data = df_with_errors[~df_with_errors['is_actual_zero']].copy()
        
        # ç¸¦è»¸çµ±ä¸€ç”¨ã«Yå€¤ã‚’åé›†
        all_y_values.extend(valid_data[pred_col].tolist())
        
        # æ•£å¸ƒå›³ä½œæˆ
        scatter = px.scatter(
            valid_data,
            x='error_rate',
            y=pred_col,
            color=color_col,
            color_discrete_map=color_discrete_map,
            hover_data=['P_code', 'Actual', pred_col, 'absolute_error_rate'],
            title=f"{get_prediction_name(pred_col)}"
        )
        
        # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã«è¿½åŠ ï¼ˆå‡¡ä¾‹ã®åå‰ã‚’åŒºåˆ†åã«å¤‰æ›´ï¼‰
        for trace in scatter.data:
            if 'Class_abc' in df.columns and trace.name in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'Z']:
                trace.name = f"{trace.name}åŒºåˆ†"
            fig.add_trace(trace, row=1, col=i+1)
        
        # Xè»¸ã«0ã®ç·šã‚’è¿½åŠ 
        fig.add_vline(x=0, line_dash="dash", line_color="gray", 
                     row=1, col=i+1, annotation_text="å®Œå…¨ä¸€è‡´")
    
    # ç¸¦è»¸ã®ç¯„å›²ã‚’çµ±ä¸€ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ã®æœ€å°ãƒ»æœ€å¤§å€¤ã«åŸºã¥ãï¼‰
    if all_y_values:
        y_min = min(all_y_values)
        y_max = max(all_y_values)
        y_margin = (y_max - y_min) * 0.05  # 5%ã®ãƒãƒ¼ã‚¸ãƒ³
        unified_y_range = [y_min - y_margin, y_max + y_margin]
    else:
        unified_y_range = None
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
    fig.update_layout(
        height=600,
        showlegend=True,
        title_text="èª¤å·®ç‡æ•£å¸ƒå›³ï¼ˆæ¨ªè»¸ï¼šèª¤å·®ç‡ ï¼ ç¸¦è»¸ï¼šè¨ˆç”»å€¤ï¼‰",
        title_font_size=16  # ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºã‚’æ˜ç¤ºçš„ã«è¨­å®š
    )
    
    # æ¨ªè»¸ã®è¨­å®šï¼ˆ+/-è¨˜å·ä»˜ãã®ç›®ç››ã‚Šï¼‰
    fig.update_xaxes(
        title_text="èª¤å·®ç‡", 
        range=[x_min_decimal, x_max_decimal],
        tickformat='+.0%',  # +/-è¨˜å·ä»˜ãã®ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸è¡¨ç¤º
        dtick=0.5  # 50%åˆ»ã¿ã§ç›®ç››ã‚Šè¡¨ç¤º
    )
    
    # ç¸¦è»¸ã®è¨­å®šï¼ˆçµ±ä¸€ç¯„å›²ï¼‰
    if unified_y_range:
        fig.update_yaxes(
            title_text="äºˆæ¸¬ãƒ»è¨ˆç”»å€¤",
            range=unified_y_range
        )
    else:
        fig.update_yaxes(title_text="äºˆæ¸¬ãƒ»è¨ˆç”»å€¤")
    
    st.plotly_chart(fig, use_container_width=True)

def create_prediction_vs_actual_scatter(df, selected_predictions):
    """äºˆæ¸¬vså®Ÿç¸¾æ•£å¸ƒå›³ã‚’ä½œæˆ"""
    
    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
    fig = make_subplots(
        rows=1, 
        cols=len(selected_predictions),
        subplot_titles=[get_prediction_name(pred) for pred in selected_predictions]
    )
    
    for i, pred_col in enumerate(selected_predictions):
        # è‰²åˆ†ã‘ç”¨ã®åˆ—ã‚’ä½œæˆï¼ˆABCåŒºåˆ†ãŒã‚ã‚Œã°ä½¿ç”¨ï¼‰
        if 'Class_abc' in df.columns:
            color_col = 'Class_abc'
            color_discrete_map = {
                'A': '#FF9999',
                'B': '#66B2FF', 
                'C': '#99FF99',
                'D': '#FFCC99',
                'E': '#FF99CC',
                'F': '#99CCFF',
                'G': '#CCFF99',
                'Z': '#FFB366'
            }
        else:
            color_col = None
            color_discrete_map = None
        
        # æ•£å¸ƒå›³ä½œæˆ
        scatter = px.scatter(
            df,
            x='Actual',
            y=pred_col,
            color=color_col,
            color_discrete_map=color_discrete_map,
            hover_data=['P_code', 'Date'],
            title=f"{get_prediction_name(pred_col)} vs å®Ÿç¸¾"
        )
        
        # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã«è¿½åŠ ï¼ˆå‡¡ä¾‹ã®åå‰ã‚’åŒºåˆ†åã«å¤‰æ›´ï¼‰
        for trace in scatter.data:
            if 'Class_abc' in df.columns and trace.name in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'Z']:
                trace.name = f"{trace.name}åŒºåˆ†"
            fig.add_trace(trace, row=1, col=i+1)
        
        # å®Œå…¨ä¸€è‡´ãƒ©ã‚¤ãƒ³ï¼ˆy=xï¼‰ã‚’è¿½åŠ 
        max_val = max(df['Actual'].max(), df[pred_col].max())
        min_val = min(df['Actual'].min(), df[pred_col].min())
        
        fig.add_trace(
            go.Scatter(
                x=[min_val, max_val], 
                y=[min_val, max_val],
                mode='lines',
                line=dict(color='red', dash='dash'),
                name='å®Œå…¨ä¸€è‡´ç·š',
                showlegend=(i == 0)  # æœ€åˆã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã®ã¿å‡¡ä¾‹è¡¨ç¤º
            ),
            row=1, col=i+1
        )
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
    fig.update_layout(
        height=600,
        showlegend=True,
        title_text="äºˆæ¸¬å€¤ vs å®Ÿç¸¾å€¤æ•£å¸ƒå›³",
        title_font_size=16  # ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºã‚’æ˜ç¤ºçš„ã«è¨­å®š
    )
    
    fig.update_xaxes(title_text="å®Ÿç¸¾å€¤")
    fig.update_yaxes(title_text="äºˆæ¸¬ãƒ»è¨ˆç”»å€¤")
    
    st.plotly_chart(fig, use_container_width=True)

def calculate_abc_average_errors(df, selected_predictions):
    """ABCåŒºåˆ†åˆ¥ã®åŠ é‡å¹³å‡èª¤å·®ç‡ã‚’è¨ˆç®—ï¼ˆå…¨åŒºåˆ†ãƒ»3ç¨®èª¤å·®ç‡å¯¾å¿œï¼‰"""
    if 'Class_abc' not in df.columns:
        return {}
    
    abc_errors = {}
    
    for pred_col in selected_predictions:
        df_with_errors = calculate_error_rates(df, pred_col, 'Actual')
        
        # ABCåŒºåˆ†åˆ¥ã®åŠ é‡å¹³å‡èª¤å·®ç‡è¨ˆç®—ï¼ˆå…¨åŒºåˆ†å¯¾å¿œãƒ»æœªåŒºåˆ†å¯¾å¿œï¼‰
        abc_stats = {}
        # æœªåŒºåˆ†ï¼ˆNaNï¼‰ã‚‚å«ã‚ã¦å‡¦ç†
        df_with_errors['Class_abc'] = df_with_errors['Class_abc'].fillna('æœªåŒºåˆ†')
        unique_abc_classes = sorted(df_with_errors['Class_abc'].unique())
        
        for abc_class in unique_abc_classes:
            abc_data = df_with_errors[df_with_errors['Class_abc'] == abc_class]
            if not abc_data.empty and len(abc_data) > 0:
                # çµ¶å¯¾èª¤å·®ç‡ã®åŠ é‡å¹³å‡
                absolute_weighted_avg = calculate_weighted_average_error_rate(
                    abc_data, 'absolute_error_rate', 'Actual'
                )
                
                # æ­£ã®èª¤å·®ç‡ï¼ˆæ­£ã®å€¤ã®ã¿ï¼‰ã®åŠ é‡å¹³å‡
                positive_data = abc_data[abc_data['error_rate'] > 0]
                if not positive_data.empty:
                    positive_weighted_avg = calculate_weighted_average_error_rate(
                        positive_data, 'error_rate', 'Actual'
                    )
                else:
                    positive_weighted_avg = 0.0
                
                # è² ã®èª¤å·®ç‡ï¼ˆè² ã®å€¤ã®ã¿ï¼‰ã®åŠ é‡å¹³å‡
                negative_data = abc_data[abc_data['error_rate'] < 0]
                if not negative_data.empty:
                    negative_weighted_avg = calculate_weighted_average_error_rate(
                        negative_data, 'error_rate', 'Actual'
                    )
                else:
                    negative_weighted_avg = 0.0
                
                abc_stats[abc_class] = {
                    'count': len(abc_data),
                    'actual_sum': abc_data['Actual'].sum(),
                    'absolute_error_rate': absolute_weighted_avg,
                    'positive_error_rate': positive_weighted_avg,
                    'negative_error_rate': negative_weighted_avg
                }
        
        abc_errors[pred_col] = abc_stats
    
    return abc_errors

def display_abc_average_table(abc_errors, filtered_df):
    """ABCåŒºåˆ†åˆ¥åŠ é‡å¹³å‡èª¤å·®ç‡ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¡¨ç¤ºï¼ˆ2æ®µãƒ˜ãƒƒãƒ€ãƒ¼ãƒ»3èª¤å·®ç‡å¯¾å¿œï¼‰"""
    if not abc_errors:
        st.info("ABCåŒºåˆ†ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # å…¨ã¦ã®äºˆæ¸¬ã‚«ãƒ©ãƒ ã‹ã‚‰å…¨ã¦ã®ABCåŒºåˆ†ã‚’å–å¾—
    all_abc_classes = set()
    for pred_col, abc_stats in abc_errors.items():
        all_abc_classes.update(abc_stats.keys())
    
    if not all_abc_classes:
        st.info("ABCåŒºåˆ†ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # ABCåŒºåˆ†ã‚’ã‚½ãƒ¼ãƒˆï¼ˆA, B, C, D...ã®é †ï¼‰
    sorted_abc_classes = sorted(list(all_abc_classes))
    
    # 2æ®µãƒ˜ãƒƒãƒ€ãƒ¼æ§‹é€ ã®MultiIndexä½œæˆ
    # ãƒ¬ãƒ™ãƒ«1: åŒºåˆ†ã€å®Ÿç¸¾åˆè¨ˆã€çµ¶å¯¾èª¤å·®ç‡ã€è² ã®èª¤å·®ç‡ã€æ­£ã®èª¤å·®ç‡
    # ãƒ¬ãƒ™ãƒ«2: AIäºˆæ¸¬, è¨ˆç”»01
    columns_level1 = ['åŒºåˆ†', 'ä»¶æ•°', 'å®Ÿç¸¾åˆè¨ˆ', 'çµ¶å¯¾èª¤å·®ç‡', 'è² ã®èª¤å·®ç‡', 'æ­£ã®èª¤å·®ç‡']
    columns_level2 = ['', '', '']  # åŒºåˆ†ã€ä»¶æ•°ã€å®Ÿç¸¾åˆè¨ˆã¯å˜åˆ—
    
    for error_type in ['çµ¶å¯¾èª¤å·®ç‡', 'è² ã®èª¤å·®ç‡', 'æ­£ã®èª¤å·®ç‡']:
        for pred_col in sorted(abc_errors.keys()):
            pred_name = get_prediction_name(pred_col)
            columns_level2.append(pred_name)
    
    # MultiIndexåˆ—ä½œæˆ
    columns_tuples = [
        ('åŒºåˆ†', ''),
        ('ä»¶æ•°', ''),
        ('å®Ÿç¸¾åˆè¨ˆ', '')
    ]
    
    for error_type in ['çµ¶å¯¾èª¤å·®ç‡', 'è² ã®èª¤å·®ç‡', 'æ­£ã®èª¤å·®ç‡']:
        for pred_col in sorted(abc_errors.keys()):
            pred_name = get_prediction_name(pred_col)
            columns_tuples.append((error_type, pred_name))
    
    multi_columns = pd.MultiIndex.from_tuples(columns_tuples)
    
    # ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    table_data = []
    total_counts = {}
    total_actual_sums = {}
    
    # äºˆæ¸¬ã‚«ãƒ©ãƒ åˆ¥ã®åˆè¨ˆã‚’è¨ˆç®—
    for pred_col in abc_errors.keys():
        total_counts[pred_col] = sum(stats['count'] for stats in abc_errors[pred_col].values())
        total_actual_sums[pred_col] = sum(stats['actual_sum'] for stats in abc_errors[pred_col].values())
    
    # ABCåŒºåˆ†åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    for abc_class in sorted_abc_classes:
        row_data = [f'{abc_class}åŒºåˆ†']
        
        # ä»¶æ•°ã¨å®Ÿç¸¾åˆè¨ˆã®è¨ˆç®—ï¼ˆå…¨äºˆæ¸¬ã®å¹³å‡ã¾ãŸã¯åˆè¨ˆï¼‰
        total_count = 0
        total_actual = 0
        
        for pred_col in sorted(abc_errors.keys()):
            if abc_class in abc_errors[pred_col]:
                stats = abc_errors[pred_col][abc_class]
                total_count = max(total_count, stats['count'])  # æœ€å¤§å€¤ã‚’ä½¿ç”¨ï¼ˆåŒã˜åŒºåˆ†ãªã®ã§ï¼‰
                total_actual = max(total_actual, stats['actual_sum'])  # æœ€å¤§å€¤ã‚’ä½¿ç”¨
        
        # ä»¶æ•°ã¨å®Ÿç¸¾åˆè¨ˆã‚’æ–‡å­—åˆ—å½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        row_data.extend([f"{total_count:,}", f"{total_actual:,.0f}"])
        
        # å„èª¤å·®ç‡ã®å€¤ã‚’è¿½åŠ ï¼ˆçµ¶å¯¾ã€è² ã€æ­£ã®é †ï¼‰
        for error_type in ['absolute_error_rate', 'negative_error_rate', 'positive_error_rate']:
            for pred_col in sorted(abc_errors.keys()):
                if abc_class in abc_errors[pred_col]:
                    error_rate = abc_errors[pred_col][abc_class][error_type]
                    if error_type == 'positive_error_rate' and error_rate != 0:
                        # æ­£ã®èª¤å·®ç‡ã«ã¯+è¨˜å·ã‚’ä»˜ã‘ã‚‹
                        formatted_rate = f"+{error_rate:.1%}"
                    else:
                        formatted_rate = f"{error_rate:.1%}"
                    row_data.append(formatted_rate)
                else:
                    # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆ
                    if error_type == 'positive_error_rate':
                        row_data.append("+0.0%")
                    else:
                        row_data.append("0.0%")
        
        table_data.append(row_data)
    
    # åˆè¨ˆè¡Œã®ä½œæˆ
    total_row_data = ['åˆè¨ˆ']
    
    # ä»¶æ•°ã¨å®Ÿç¸¾åˆè¨ˆã®åˆè¨ˆ
    grand_total_count = sum(total_counts.values()) // len(total_counts) if total_counts else 0  # é‡è¤‡æ’é™¤
    grand_total_actual = sum(total_actual_sums.values()) // len(total_actual_sums) if total_actual_sums else 0  # é‡è¤‡æ’é™¤
    
    # ã‚ˆã‚Šæ­£ç¢ºãªåˆè¨ˆè¨ˆç®—ï¼ˆæœ€åˆã®äºˆæ¸¬ã‚«ãƒ©ãƒ ã‹ã‚‰å…¨ãƒ‡ãƒ¼ã‚¿ã®åˆè¨ˆã‚’è¨ˆç®—ï¼‰
    if abc_errors:
        first_pred = list(abc_errors.keys())[0]
        grand_total_count = sum(stats['count'] for stats in abc_errors[first_pred].values())
        grand_total_actual = sum(stats['actual_sum'] for stats in abc_errors[first_pred].values())
    
    # åˆè¨ˆè¡Œã‚‚æ–‡å­—åˆ—å½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    total_row_data.extend([f"{grand_total_count:,}", f"{grand_total_actual:,.0f}"])
    
    # å„èª¤å·®ç‡ã®å…¨ä½“åŠ é‡å¹³å‡ã‚’è¨ˆç®—
    for error_type in ['absolute_error_rate', 'negative_error_rate', 'positive_error_rate']:
        for pred_col in sorted(abc_errors.keys()):
            # å…¨ä½“ã®åŠ é‡å¹³å‡ã‚’è¨ˆç®—ï¼ˆæ­£è² ã®å ´åˆã¯è©²å½“ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
            if error_type == 'positive_error_rate':
                # æ­£ã®èª¤å·®ç‡ã®ã¿ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                df_with_errors = calculate_error_rates(filtered_df, pred_col, 'Actual')
                positive_data = df_with_errors[df_with_errors['error_rate'] > 0]
                
                if len(positive_data) > 0:
                    overall_rate = calculate_weighted_average_error_rate(positive_data, 'error_rate', 'Actual')
                    formatted_rate = f"+{overall_rate:.1%}"
                else:
                    formatted_rate = "+0.0%"
                    
            elif error_type == 'negative_error_rate':
                # è² ã®èª¤å·®ç‡ã®ã¿ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                df_with_errors = calculate_error_rates(filtered_df, pred_col, 'Actual')
                negative_data = df_with_errors[df_with_errors['error_rate'] < 0]
                
                if len(negative_data) > 0:
                    overall_rate = calculate_weighted_average_error_rate(negative_data, 'error_rate', 'Actual')
                    formatted_rate = f"{overall_rate:.1%}"
                else:
                    formatted_rate = "0.0%"
                    
            else:  # absolute_error_rate
                # çµ¶å¯¾èª¤å·®ç‡ï¼ˆå¾“æ¥é€šã‚Šï¼‰
                total_weighted_sum = 0
                total_weight = 0
                
                for abc_class, stats in abc_errors[pred_col].items():
                    error_rate = stats[error_type]
                    weight = stats['actual_sum']
                    total_weighted_sum += error_rate * weight
                    total_weight += weight
                
                if total_weight > 0:
                    overall_rate = total_weighted_sum / total_weight
                    formatted_rate = f"{overall_rate:.1%}"
                else:
                    formatted_rate = "0.0%"
            
            total_row_data.append(formatted_rate)
    
    table_data.append(total_row_data)
    
    # DataFrameä½œæˆ
    df_table = pd.DataFrame(table_data, columns=multi_columns)
    
    # æ³¨è¨˜ä»˜ãã§ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º
    st.markdown("### ABCåŒºåˆ†åˆ¥ åŠ é‡å¹³å‡èª¤å·®ç‡ï¼ˆçµ¶å¯¾å€¤ãƒ»è² æ–¹å‘ãƒ»æ­£æ–¹å‘ï¼‰")
    st.markdown("**â€» èª¤å·®ç‡ã¯å®Ÿç¸¾å€¤ã§é‡ã¿ã¥ã‘ã—ãŸåŠ é‡å¹³å‡**")
    
    # ã‚«ã‚¹ã‚¿ãƒ CSS for ç­‰å¹…åˆ—
    table_css = """
    <style>
    .stDataFrame > div {
        width: 100%;
    }
    .stDataFrame table {
        width: 100% !important;
    }
    .stDataFrame th, .stDataFrame td {
        text-align: center !important;
        width: 11.11% !important;  /* 9åˆ—ãªã®ã§å„åˆ—ç´„11% */
        min-width: 80px !important;
    }
    .stDataFrame th:first-child, .stDataFrame td:first-child {
        width: 12% !important;  /* åŒºåˆ†åˆ—ã‚’ã‚„ã‚„åºƒã */
    }
    </style>
    """
    st.markdown(table_css, unsafe_allow_html=True)
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºï¼ˆcolumn_configãªã—ã§ã‚·ãƒ³ãƒ—ãƒ«ã«ï¼‰
    st.dataframe(
        df_table,
        use_container_width=True,
        hide_index=True
    ) 